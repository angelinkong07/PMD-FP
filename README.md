# PMD-FP
“Cazulang: Intelligent Voice-Guided Navigation for the Visually Impaired” is an innovative mobile application designed to address the critical need for inclusive, accessible, and intelligent navigation solutions for individuals who are blind or have low vision. In today’s world, independence and mobility are fundamental to personal freedom, professional participation, and social inclusion. However, most navigation systems remain predominantly visual, creating significant accessibility barriers for the visually impaired community. Cazulang seeks to overcome these barriers by combining cutting-edge technologies such as voice recognition, haptic feedback, and real-time location tracking into one user-centric solution.

At the heart of this project is the goal to provide a multi-sensory, intuitive, and context-aware navigation experience. By enabling voice-guided interaction, users can set destinations, receive turn-by-turn auditory instructions, and request situational updates – all hands-free. To further support users in visually complex or noisy environments, the application integrates haptic feedback via customised vibration patterns to convey directional cues, alerts for nearby obstacles, and transitions within indoor and outdoor settings. These features are carefully designed to enhance spatial awareness, reduce dependence on visual cues, and ultimately promote safer, more confident navigation.

The primary goal of Cazulang is to enhance navigation precision, especially in micro-navigation scenarios such as locating a bus stop, crossing intersections, or entering specific building entrances. Through spatial recognition and accurate location tracking, the application aims to deliver highly precise and adaptive guidance, allowing users to navigate with minimal uncertainty. Real-time data processing ensures that route adjustments are responsive to environmental changes and user behaviour, improving both usability and safety.

Secondly, Cazulang aims to transform the accessibility of navigation interfaces by ensuring full compatibility with screen readers and assistive technologies. The interface is built with simplicity, clarity, and function in mind, where interactive elements are designed with descriptive audio feedback, while intuitive voice commands and customisable settings empower users to control the experience according to their preferences. This approach aligns with inclusive design principles, ensuring that the system is not only usable but truly empowering for its target users.

Lastly, Cazulang focuses on delivering context-aware navigation support, recognising the challenges posed by dynamic and unpredictable environments. By integrating obstacle detection, dynamic rerouting, and proactive safety alerts, the application adapts to real-world conditions in real time. This reduces the risks associated with hazards such as construction zones, uneven surfaces, or missing tactile paving and ensures that users are informed, safe, and supported in every step of their journey.

The expected outcomes of this project extend beyond technology. Cazulang aspires to reduce social and mobility-related inequalities by providing a robust tool that promotes independence and dignity for the visually impaired. Through thoughtful design and innovative engineering, this project paves the way for a more inclusive future, one in which accessibility is not an afterthought but a foundational element of smart city mobility systems.
